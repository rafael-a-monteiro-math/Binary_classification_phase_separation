{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97b9e468",
   "metadata": {},
   "source": [
    "# PSBC - training notebook\n",
    "\n",
    "Goal: perform PSBC model evaluation on a grid in the folder \"../Grids\", on the main folder.\n",
    "\n",
    "How: \n",
    "\n",
    "Input: \n",
    "* Neumann: bool (True or False), denotes the type of Boundary condition.\n",
    "* subordinate: bool (True or False, default is True) to describe the type of model\n",
    "* parallel: bool (True or False, default is False), in case the model is parallel\n",
    "* with_PCA: bool (True or False, default is False), in case a different basis matrix is used\n",
    "\n",
    "\n",
    "Initially, we need to allow google drive to access the folders with files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dd695a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Colab = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0528861",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23740,
     "status": "ok",
     "timestamp": 1628045789805,
     "user": {
      "displayName": "Rafael Monteiro",
      "photoUrl": "",
      "userId": "14710212060218227899"
     },
     "user_tz": -540
    },
    "id": "ee9817df",
    "outputId": "ab742c27-0ff5-4f4f-a81e-b67b545772f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "if Colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount ('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514cb1f0",
   "metadata": {
    "id": "c873ca64"
   },
   "outputs": [],
   "source": [
    "#import  matplotlib.pyplot as plt\n",
    "import scipy.sparse as sc\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import shutil \n",
    "import copy\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "try: ## In order to open and save dictionaries, \"dt\": self.dt, \"kind\" : \"Viscosity\"\n",
    "    import cPickle as pickle\n",
    "except ImportError:  # python 3.x\n",
    "    import pickle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import multiprocess as mp\n",
    "warnings.filterwarnings (action = \"ignore\", message = \"internal issue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dea455c",
   "metadata": {},
   "source": [
    "At this moment we are in the folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c900c6b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1628045792491,
     "user": {
      "displayName": "Rafael Monteiro",
      "photoUrl": "",
      "userId": "14710212060218227899"
     },
     "user_tz": -540
    },
    "id": "13c72263",
    "outputId": "f9f3fe79-0c82-4b12-8e83-872a84cc2cfd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_now = os.getcwd ()\n",
    "print (folder_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04893a9b",
   "metadata": {},
   "source": [
    "We then move to the folder we need, and import the folder with all the libraries we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b9e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Colab: \n",
    "    os.chdir (\"/content/drive/MyDrive/PSBC/\")\n",
    "\n",
    "sys.path.insert (0, \"MOTHER_PSBC/\")\n",
    "folder_now = os.getcwd ()\n",
    "print (folder_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6285f",
   "metadata": {},
   "source": [
    "which are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0c529",
   "metadata": {
    "id": "2de149c5"
   },
   "outputs": [],
   "source": [
    "from tfversion_binary_phase_separation import *\n",
    "from tf_PSBC_extra_libs_for_training_and_grid_search import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0f0c8a",
   "metadata": {},
   "source": [
    "Now we acccess the appropriate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b1e5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Folder options are 'Neumann', 'Periodic', 'PCA_196', 'Classifier_196'\")\n",
    "\n",
    "which_folder = \"Neumann\"\n",
    "\n",
    "os.chdir (which_folder)\n",
    "\n",
    "print (\"\\n\\nNow we are in folder\", os.getcwd ())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a482012",
   "metadata": {
    "id": "67134b0d"
   },
   "source": [
    "## Setting up parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8226c14f",
   "metadata": {
    "id": "2196ae9e"
   },
   "outputs": [],
   "source": [
    "if which_folder in ['Neumann', 'Periodic','Neumann_non_subordinate']:\n",
    "    print (\n",
    "        \"\\tRecall that grid search happens at eps = 0, hence models with\\n\"+\\\n",
    "        \"\\t Neumann and Periodic BCs are the same, because no diffusion is in place\\n\\n\"\n",
    "        )\n",
    "    Neumann = not (which_folder == 'Periodic')\n",
    "    subordinate = not (which_folder == 'Neumann_non_subordinate')\n",
    "    with_PCA = False     \n",
    "    parallel = False\n",
    "    cpu = 4  ## In case of parallel processing\n",
    "    Nx = 784\n",
    "    classifier = False\n",
    "elif which_folder == 'PCA_196':\n",
    "    Neumann = True\n",
    "    subordinate = True\n",
    "    with_PCA = True\n",
    "    parallel = False\n",
    "    cpu = 4  ## In case of parallel processing\n",
    "    Nx = 784\n",
    "    classifier = True\n",
    "elif which_folder == 'Classifier_196':\n",
    "    Neumann = True\n",
    "    Nt = 2\n",
    "    save_history = True\n",
    "    subordinate = True\n",
    "    with_PCA = False     \n",
    "    parallel = False\n",
    "    cpu = 4  ## In case of parallel processing\n",
    "    Nx = 784\n",
    "    classifier = True\n",
    "\n",
    "grid_type =  \"training\"\n",
    "    \n",
    "print (\"The model will perform \\n\", grid_type,\n",
    "       \"\\nwith the following parameters:\\n* Neumann is\",\n",
    "       Neumann, \"\\n* with_PCA is\", with_PCA,\n",
    "       \"\\n* subordinate is\", subordinate,\"\\n* parallel is\",\\\n",
    "       parallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7e5d65",
   "metadata": {
    "id": "2776a909"
   },
   "source": [
    "## Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca96d4",
   "metadata": {
    "id": "51404d4c"
   },
   "outputs": [],
   "source": [
    "if which_folder == 'PCA_196':\n",
    "    nt_range  = [2]\n",
    "    digits_range = [0,1]  ## Will be ignored\n",
    "    pairs_of_digits = [(4,9), (3, 5)]    \n",
    "elif which_folder == 'Classifier_196':\n",
    "    nt_range  = [2]\n",
    "    digits_range = np.arange (0,45)\n",
    "else:\n",
    "    nt_range = [1,2,4]\n",
    "    digits_range = [0]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccf74de",
   "metadata": {},
   "source": [
    "> **Remark** : if you are running this model in Colab you'd better use TPUs or GPUs to speed up training. In this case it is also convenient to break the processing in cases, doing one folder Nt at a time, or chopping the digits_range in pieces, in case of classifiers. \n",
    "In general, each batch evaluation runs pretty fast, and setting EPOCHS larger than 10 was a bit of an overkill. You can change that if you want. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7cbe27",
   "metadata": {
    "id": "5d4a65fd"
   },
   "source": [
    "# Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfacef7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11230,
     "status": "ok",
     "timestamp": 1628045840497,
     "user": {
      "displayName": "Rafael Monteiro",
      "photoUrl": "",
      "userId": "14710212060218227899"
     },
     "user_tz": -540
    },
    "id": "552b742a",
    "outputId": "351d9522-7353-42ed-839f-6bf8889c9658",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for weight_k_share :  [1] and partition cardinality  [784]\n",
      "\n",
      " Parameters in use : {'eps_range': array([0.], dtype=float32), 'dt_range': array([0.2], dtype=float32), 'ptt_range': array([784], dtype=uint16), 'layer_share_range': array([1], dtype=uint16), 'lr_U_range': array([0.1], dtype=float32), 'lr_P_range': array([0.001], dtype=float32)}\n",
      "\n",
      "RUNNING THE MODEL SERIALLY\n",
      "\n",
      "Fixed hyperparameters\n",
      "\n",
      "Nx : 784 \tNt : 1 \tNeumann : True \tpatience : 10 \ttrain_dt_U : True \ttrain_dt_P : True \n",
      "\twith_PCA : False\n",
      "\n",
      "\n",
      "\tWe will fit the model 1 times\n",
      "\n",
      "\n",
      "\n",
      "Varying parameters time \n",
      " 0\n",
      "eps : 0.0 \tdt : 0.2 \tptt_cardnlty : 784 \tlayers_K_shared : 1 \tlr_U : 0.1 \tlr_P : 0.001\n",
      "Setting up a subordinate model with phase\n",
      "Setting up a basic layer with Neumann B.C.s.\n",
      "Setting up a basic layer with Neumann B.C.s.\n",
      "Model: \"psbc_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_layer_2 (Zero_layer)    multiple                  1         \n",
      "_________________________________________________________________\n",
      "augment_layer_1 (Augment_lay multiple                  1         \n",
      "_________________________________________________________________\n",
      "psbc_u_and_p_1 (PSBC_U_and_P multiple                  1568      \n",
      "_________________________________________________________________\n",
      "final_layer_1 (Final_layer)  multiple                  0         \n",
      "=================================================================\n",
      "Total params: 1,570\n",
      "Trainable params: 1,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Save best model as weights/0_0_784_1_0_0_fold_0_Index_1_784_1.h5\n",
      "\n",
      "filepath weights/0_0_784_1_0_0_fold_0_Index_1_784_1\n",
      "Validation data available\n",
      "Epoch 1/2\n",
      "Training dt_U\n",
      "Training dt_P\n",
      "Training dt_U\n",
      "Training dt_P\n",
      "396/396 [==============================] - 2s 3ms/step - loss: 0.2493 - classify_zero_one: 0.9888 - ||W_U||_{infty} : 1.0000 - ||W_P||_{infty} : 7.7864 - dt_U : 0.5700 - dt_P : 0.0199\n",
      "\n",
      "\n",
      "Accuracy on the validation data 0.9902092 \n",
      "\n",
      "Epoch 2/2\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2496 - classify_zero_one: 0.9897 - ||W_U||_{infty} : 1.0000 - ||W_P||_{infty} : 12.0460 - dt_U : 0.5700 - dt_P : 0.0040\n",
      "\n",
      "\n",
      "Accuracy on the validation data 0.9895776 \n",
      "\n",
      "\n",
      "End of training\n",
      "\n",
      "Saving validation data accuracy data\n",
      "[0.24911173, 0.9902092, 0.9895776]\n",
      "\n",
      "Saving validation data accuracy weights and data as pickled file\n",
      "weights/0_0_784_1_0_0_fold_0_Index_1_784_1\n",
      "weights/0_0_784_1_0_0_fold_0_Index_1_784_1 weights/0_0_784_1_0_0_fold_0_Index_1_784_1_val_accuracy.p\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Saving the model\n",
      "Model's weights saved in pickled file as  weights/0_0_784_1_0_0_fold_0_Index_1_784_1_best_weights\n",
      "\n",
      "Accuracy on the validation data per epoch [0.24911173, 0.9902092, 0.9895776]\n",
      "Maximal accuracy was 0.9902092\n",
      "\n",
      "Fixed hyperparameters\n",
      "\n",
      "Nx : 784 \tNt : 1 \tNeumann : True \tpatience : 10 \ttrain_dt_U : True \ttrain_dt_P : True \n",
      "\twith_PCA : False\n",
      "\n",
      "\n",
      "\tWe will fit the model 1 times\n",
      "\n",
      "\n",
      "\n",
      "Varying parameters time \n",
      " 0\n",
      "eps : 0.0 \tdt : 0.2 \tptt_cardnlty : 784 \tlayers_K_shared : 1 \tlr_U : 0.1 \tlr_P : 0.001\n",
      "Setting up a subordinate model with phase\n",
      "Setting up a basic layer with Neumann B.C.s.\n",
      "Setting up a basic layer with Neumann B.C.s.\n",
      "Model: \"psbc_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_layer_4 (Zero_layer)    multiple                  1         \n",
      "_________________________________________________________________\n",
      "augment_layer_2 (Augment_lay multiple                  1         \n",
      "_________________________________________________________________\n",
      "psbc_u_and_p_2 (PSBC_U_and_P multiple                  1568      \n",
      "_________________________________________________________________\n",
      "final_layer_2 (Final_layer)  multiple                  0         \n",
      "=================================================================\n",
      "Total params: 1,570\n",
      "Trainable params: 1,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Save best model as weights/0_0_784_1_0_0_fold_1_Index_1_784_1.h5\n",
      "\n",
      "filepath weights/0_0_784_1_0_0_fold_1_Index_1_784_1\n",
      "Validation data available\n",
      "Epoch 1/2\n",
      "Training dt_U\n",
      "Training dt_P\n",
      "Training dt_U\n",
      "Training dt_P\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.2493 - classify_zero_one: 0.9896 - ||W_U||_{infty} : 1.0000 - ||W_P||_{infty} : 7.8717 - dt_U : 0.5700 - dt_P : 0.0204\n",
      "\n",
      "\n",
      "Accuracy on the validation data 0.9904461 \n",
      "\n",
      "Epoch 2/2\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.2496 - classify_zero_one: 0.9901 - ||W_U||_{infty} : 1.0000 - ||W_P||_{infty} : 12.2277 - dt_U : 0.5700 - dt_P : 0.0039\n",
      "\n",
      "\n",
      "Accuracy on the validation data 0.9896565 \n",
      "\n",
      "\n",
      "End of training\n",
      "\n",
      "Saving validation data accuracy data\n",
      "[0.5294907, 0.9904461, 0.9896565]\n",
      "\n",
      "Saving validation data accuracy weights and data as pickled file\n",
      "weights/0_0_784_1_0_0_fold_1_Index_1_784_1\n",
      "weights/0_0_784_1_0_0_fold_1_Index_1_784_1 weights/0_0_784_1_0_0_fold_1_Index_1_784_1_val_accuracy.p\n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Saving the model\n",
      "Model's weights saved in pickled file as  weights/0_0_784_1_0_0_fold_1_Index_1_784_1_best_weights\n",
      "\n",
      "Accuracy on the validation data per epoch [0.5294907, 0.9904461, 0.9896565]\n",
      "Maximal accuracy was 0.9904461\n",
      "Creating Accuracies and parameter pickled file\n",
      "Statistics pickled to  Training_accuracies_1_784_1_vary_eps_0_1.p\n"
     ]
    }
   ],
   "source": [
    "with open (\"../Grids/digits_index.p\", 'rb') as pickled_dic:\n",
    "    grid_indexes  = pickle.load (pickled_dic)\n",
    "\n",
    "for index in digits_range:\n",
    "    \n",
    "    if with_PCA:\n",
    "            variable_0, variable_1 = pairs_of_digits [index]\n",
    "    else:\n",
    "        variable_0, variable_1 = grid_indexes [index] \n",
    "\n",
    "    for Nt in nt_range:\n",
    "        \n",
    "        os.chdir (str (Nt))\n",
    "        \n",
    "        ### READ VARIABLES AND RETRIEVE TRAINING DATA (BOTH VARIABLES COMBINED)\n",
    "        \n",
    "        filename = \"training_\" + str (Neumann)+ \"_\" + str (Nt) + \".p\"\n",
    "        with open (\"../../Grids/\" + filename, 'rb') as pickled_dic:\n",
    "            grid_range  = pickle.load (pickled_dic)\n",
    "\n",
    "        cv = grid_range [\"cv\"]\n",
    "\n",
    "        ############################################\n",
    "        print (\"Asserting Nt\")\n",
    "        assert (grid_range[\"Nt\"] == Nt)\n",
    "        print (\"Asserting Neumann\")\n",
    "        assert (grid_range[\"Neumann\"] == Neumann)\n",
    "        print (grid_range)\n",
    "        ############################################\n",
    "\n",
    "        EPOCHS = grid_range [\"EPOCHS\"]\n",
    "        patience = grid_range [\"patience\"]\n",
    "        Nt = grid_range [\"Nt\"]\n",
    "        train_dt_U = grid_range [\"train_dt_U\"]\n",
    "        train_dt_P = grid_range [\"train_dt_P\"]\n",
    "\n",
    "        print (\"\\n* Number of cross valications :\", cv)\n",
    "        print (\"Variables given:\\n\\tvariable_0 :\", variable_0,\"\\n\\tvariable_1 :\", variable_1)\n",
    "        print (\"\\n* Parallel is\", parallel, \". (If parallel is True, then use \", cpu,\" cores.)\")\n",
    "        print (\"\\n* Nx :\", Nx, \", Neumann :\", Neumann, \", Epochs : \", EPOCHS, \", Patience : \", patience)\n",
    "        print (\"\\n* Nt :\",  Nt, \", train_dt_U :\", train_dt_U, \", train_dt_P :\", train_dt_P)\n",
    "        print (\"\\n* with_PCA :\", with_PCA)\n",
    "\n",
    "        ### SELECTING TRAINING SET\n",
    "        S = select_split_pickle (level = 2)\n",
    "        X_train, Y_train, _, _, _ = prepare_train_test_set (variable_0, variable_1, level = 2)\n",
    "        \n",
    "        all_results = []\n",
    "        \n",
    "        ### RETRIEVING PRINCIPAL COMPONENTS IF NECESSARY\n",
    "        if with_PCA:\n",
    "            print (\"Model with PCA : retrieving principal components\")\n",
    "            _, _, Vstar = np.linalg.svd (X_train)\n",
    "        else:\n",
    "            Vstar = None\n",
    "        \n",
    "        print (\"Constructing GRIDS with best hyperparameters!!!\")\n",
    "        \n",
    "        retrieve_best_par = BestPararameters_ptt_card_weights_k_shared_fixed (\n",
    "              Nt, variable_0, variable_1, classifier = classifier, with_PCA = with_PCA)\n",
    "\n",
    "        parameters_model_1, parameters_model_Nt = fill_parameters_dict (\n",
    "            Nt,  retrieve_best_par,\n",
    "            weight_sharing_split = True, classifier = True)\n",
    "\n",
    "        all_parameters = {**parameters_model_1, **parameters_model_Nt}\n",
    "        all_keys = list(all_parameters.keys())\n",
    "\n",
    "        for key in all_parameters.keys():\n",
    "            X_train, Y_train, _, _, _ =\\\n",
    "            prepare_train_test_set (variable_0, variable_1, level = 2)\n",
    "\n",
    "            parameters_now = all_parameters [key]\n",
    "\n",
    "            assert (key [0] == parameters_now [\"layer_share_range\"])\n",
    "            assert (key [1] == parameters_now [\"ptt_range\"])\n",
    "\n",
    "            print (\n",
    "                \"Training the model for weight_k_share : \", parameters_now [\"layer_share_range\"],\\\n",
    "                 \"and partition cardinality \", parameters_now [\"ptt_range\"]\n",
    "            )\n",
    "            \n",
    "            if which_folder in ['PCA_196', 'Classifier_196']:\n",
    "                append_to_saved_file_name = \"_var0_\" + str (variable_0) + \"_var1_\" + str (variable_1)\n",
    "                if which_folder in ['PCA_196']:\n",
    "                    append_to_saved_file_name = \"_PCA_\" + append_to_saved_file_name\n",
    "            else:\n",
    "                append_to_saved_file_name = \"_Index_\"+ str (key [0]) + \"_\" + str (key [1]) + \"_\" + str (Nt)\n",
    "\n",
    "            print (\"\\n Parameters in use :\", parameters_now)\n",
    "\n",
    "            all_results = fitting_several_models(\n",
    "                cv, parallel, cpu, X_train, Y_train, X_train, Y_train, parameters_now,\n",
    "                Nx, Neumann, EPOCHS, patience, Nt, train_dt_U, train_dt_P,\n",
    "                with_PCA, Vstar, save_best_only = True,\n",
    "                append_to_saved_file_name = append_to_saved_file_name,\n",
    "                save_history = True,\n",
    "                subordinate = subordinate)\n",
    "\n",
    "            #return results\n",
    "            for j, a, b in all_results:\n",
    "                if  j == 0:\n",
    "                    Accuracies, Parameters = a [np.newaxis,:], b\n",
    "                else:\n",
    "                    Accuracies_tmp, Parameters_tmp = a [np.newaxis,:], b\n",
    "                    assert (Parameters_tmp == Parameters)\n",
    "                    Accuracies = np.vstack ([Accuracies, Accuracies_tmp]) \n",
    "\n",
    "            try: os.mkdir (\"training\")\n",
    "            except: pass\n",
    "\n",
    "            print (\"Creating Accuracies and parameter pickled file\")\n",
    "            if which_folder in ['PCA_196', 'Classifier_196']:\n",
    "                file_name =\\\n",
    "                \"Training_accuracies_\" + str (key [0]) + \"_\" + str (key [1]) +\\\n",
    "                \"_\" + str (Nt)+\"_classifier_\"+ str (variable_0)+ \"_\" +\\\n",
    "                str (variable_1)+\".p\"\n",
    "                \n",
    "                if which_folder in ['PCA_196']:\n",
    "                    file_name = \"PCA_\" + file_name\n",
    "            else:\n",
    "                file_name = \"Training_accuracies_\"+ str (key [0])+\\\n",
    "                \"_\" + str (key [1]) + \"_\" + str (Nt)+\"_vary_eps_\" +\\\n",
    "                str (variable_0)+ \"_\" + str (variable_1)+\".p\"\n",
    "            \n",
    "            file_name = \"training/\" + file_name\n",
    "            \n",
    "            with open (file_name, 'wb') as save:\n",
    "                pickle.dump ((Accuracies, Parameters), save, protocol = pickle.HIGHEST_PROTOCOL)        \n",
    "                print (\"Statistics pickled to \", file_name)\n",
    "            \n",
    "            evaluate_model (\n",
    "                *key, Nt, variable_0, variable_1, all_parameters,\n",
    "                Neumann = Neumann, classifier = classifier,\n",
    "                with_PCA = with_PCA, subordinate = subordinate)\n",
    "        \n",
    "        os.chdir (\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfed1838",
   "metadata": {
    "id": "0ea8f2ea"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Train_model_colab_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.5.2 64-bit",
   "language": "python",
   "name": "python35264bitd4a6bc6e7d32428089f28658c6d0f50c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
